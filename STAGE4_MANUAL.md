# ç¬¬å››é˜¶æ®µæ“ä½œæ‰‹å†Œ

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®å·²å®Œæˆç¬¬å››é˜¶æ®µå®ç°ï¼Œå»ºç«‹äº†å®Œæ•´çš„ **LLM é©±åŠ¨å™äº‹ç”Ÿæˆä½“ç³»**ã€‚æ‰€æœ‰å™äº‹æ–‡æœ¬å’Œç©å®¶é€‰é¡¹å‡ç”± LLM å®æ—¶ç”Ÿæˆï¼Œæ¸¸æˆå¼•æ“ä»…è´Ÿè´£è§„åˆ™åˆ¤å®šå’ŒçŠ¶æ€ç®¡ç†ã€‚

### æ ¸å¿ƒåŸåˆ™ï¼ˆå·²ä¸¥æ ¼éµå®ˆï¼‰

âœ… **LLM ä¸æ˜¯æ¸¸æˆå¼•æ“** - ä¸å†³å®šæ•°å€¼ã€æˆåŠŸ/å¤±è´¥ã€æ¸¸æˆçŠ¶æ€
âœ… **LLM å”¯ä¸€èŒè´£** - ç”Ÿæˆå™äº‹æ–‡æœ¬ + é€‰é¡¹åˆ—è¡¨
âœ… **å¼ºåˆ¶ç»“æ„åŒ– I/O** - è¾“å…¥/è¾“å‡ºå‡ä¸º JSONï¼Œæœ‰å®Œæ•´ schema æ ¡éªŒ

---

## ğŸš€ å¿«é€Ÿå¯åŠ¨

### 1. å¯åŠ¨æœåŠ¡å™¨ï¼ˆåç«¯ï¼‰

```bash
cd packages/server
npm install
npm run dev
```

æœåŠ¡å™¨å°†åœ¨ `http://localhost:3001` å¯åŠ¨

### 2. å¯åŠ¨å®¢æˆ·ç«¯ï¼ˆå‰ç«¯ï¼‰

```bash
cd packages/client
npm install
npm run dev
```

å®¢æˆ·ç«¯å°†åœ¨ `http://localhost:3000` å¯åŠ¨

### 3. è®¿é—®æ¸¸æˆç•Œé¢

åœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼š

```
http://localhost:3000/demo
```

è¿™æ˜¯å®Œæ•´çš„ LLM é©±åŠ¨æ¸¸æˆç•Œé¢ã€‚

---

## ğŸ® æ¸¸æˆç•Œé¢è¯´æ˜

### å½“å‰ demo ç•Œé¢æ˜¯æ­£è§„æ¸¸æˆç•Œé¢

**é‡è¦è¯´æ˜**ï¼š`/demo` è·¯ç”±ç°åœ¨ä½¿ç”¨çš„æ˜¯**å®Œæ•´çš„ LLM é©±åŠ¨æ¸¸æˆç•Œé¢**ï¼Œä¸æ˜¯æµ‹è¯•ç•Œé¢ã€‚

- âœ… **å¼ºåˆ¶æ¥å…¥ LLM**ï¼šæ‰€æœ‰å™äº‹å’Œé€‰é¡¹éƒ½ç”± LLM ç”Ÿæˆ
- âœ… **åœºæ™¯ç³»ç»Ÿ**ï¼šä» `scenes/zone_01/` åŠ è½½åœºæ™¯æ•°æ®
- âœ… **ä¸Šä¸‹æ–‡æ„é€ **ï¼šæ¯æ¬¡è°ƒç”¨ LLM æ—¶æ„é€ å®Œæ•´ä¸Šä¸‹æ–‡
- âœ… **ç»“æ„åŒ– I/O**ï¼šä¸¥æ ¼ JSON schema æ ¡éªŒ
- âœ… **é™çº§ç­–ç•¥**ï¼šLLM å¤±è´¥æ—¶è‡ªåŠ¨ä½¿ç”¨ fallback

### æ¸¸æˆæµç¨‹

1. **å¼€å§‹æ¸¸æˆ** â†’ åˆå§‹åŒ–ç©å®¶çŠ¶æ€ï¼ŒåŠ è½½ zone_01 åœºæ™¯
2. **LLM ç”Ÿæˆ** â†’ è°ƒç”¨ `/api/game/step` æ¥å£ï¼ŒLLM ç”Ÿæˆå™äº‹å’Œé€‰é¡¹
3. **ç©å®¶é€‰æ‹©** â†’ ç‚¹å‡»é€‰é¡¹ï¼Œè§„åˆ™å¼•æ“è®¡ç®—åæœ
4. **æ›´æ–°çŠ¶æ€** â†’ çŠ¶æ€å˜åŒ–è¢«è®°å½•åˆ°å†å²æ‘˜è¦
5. **å¾ªç¯** â†’ é‡å¤æ­¥éª¤ 2-4

---

## ğŸ“ é¡¹ç›®æ¶æ„

### åç«¯æœåŠ¡å±‚ï¼ˆå®Œæ•´å®ç°ï¼‰

```
packages/server/src/services/
â”œâ”€â”€ scene-loader.ts          # åœºæ™¯åŠ è½½å™¨ï¼ˆä» scenes/ ç›®å½•ï¼‰
â”œâ”€â”€ context-builder.ts       # ä¸Šä¸‹æ–‡æ„é€ å™¨ï¼ˆæ„é€  LLM è¾“å…¥ï¼‰
â”œâ”€â”€ prompt-renderer.ts       # Prompt æ¨¡æ¿æ¸²æŸ“å™¨
â”œâ”€â”€ llm-client.ts            # LLM è°ƒç”¨å®¢æˆ·ç«¯ï¼ˆæ”¯æŒ mock/openai/anthropicï¼‰
â”œâ”€â”€ schema-validator.ts      # JSON Schema æ ¡éªŒå™¨
â””â”€â”€ game-step-controller.ts  # æ¸¸æˆæ­¥éª¤æ§åˆ¶å™¨ï¼ˆåè°ƒæ‰€æœ‰æœåŠ¡ï¼‰
```

### Prompt æ¨¡æ¿ç³»ç»Ÿ

```
prompts/
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ scene_and_choices.prompt.md  # å™äº‹ç”Ÿæˆ prompt æ¨¡æ¿
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ llm_input.schema.json        # LLM è¾“å…¥ schema
â”‚   â””â”€â”€ llm_output.schema.json       # LLM è¾“å‡º schema
â””â”€â”€ README.md                        # Prompt ç³»ç»Ÿè¯´æ˜
```

### åœºæ™¯ç³»ç»Ÿ

```
scenes/
â””â”€â”€ zone_01/                         # åœºæ™¯ ID
    â”œâ”€â”€ scene.json                   # åœºæ™¯æ•°æ®ï¼ˆå¿…éœ€ï¼‰
    â”œâ”€â”€ items.json                   # é“å…·æ•°æ®ï¼ˆå¯é€‰ï¼‰
    â”œâ”€â”€ background.jpg               # èƒŒæ™¯å›¾ï¼ˆå¯é€‰ï¼‰
    â””â”€â”€ background.gif               # åŠ¨ç”»èƒŒæ™¯ï¼ˆå¯é€‰ï¼‰
```

---

## ğŸ“ æ·»åŠ æ–°åœºæ™¯ï¼ˆæ“ä½œæŒ‡å—ï¼‰

### æ­¥éª¤ 1ï¼šåˆ›å»ºåœºæ™¯ç›®å½•

```bash
mkdir scenes/zone_02
```

### æ­¥éª¤ 2ï¼šåˆ›å»º scene.json

åœ¨ `scenes/zone_02/scene.json` ä¸­ï¼š

```json
{
  "sceneId": "zone_02",
  "name": "åºŸå¼ƒç ”ç©¶ç«™",
  "theme": ["urban", "decay", "technology"],
  "description": "ä¸€ä¸ªåºŸå¼ƒçš„å¼‚å¸¸ç ”ç©¶ç«™ç‚¹ï¼Œå»ºç­‘ç»“æ„ä¸ç¨³å®šï¼Œå……æ»¡æœªçŸ¥çš„è®¾å¤‡æ®‹éª¸å’Œæ•°æ®è®°å½•ã€‚è¿™é‡Œæ›¾ç»æ˜¯ç¦åŒºç ”ç©¶çš„å‰å“¨ç«™ï¼Œä½†åœ¨æŸæ¬¡äº‹æ•…åè¢«ç´§æ€¥æ’¤ç¦»ã€‚",
  "allowedEvents": ["exploration", "discovery", "anomaly", "danger"],
  "possibleItems": ["item_003", "item_004"],
  "dangerLevel": 5,
  "background": {
    "preferred": "background.jpg",
    "fallbackColor": "#1a1d23"
  },
  "rules": {
    "maxSteps": 20,
    "evacuationAvailable": false,
    "deathIsPermament": false
  }
}
```

### æ­¥éª¤ 3ï¼šæ·»åŠ èƒŒæ™¯å›¾ï¼ˆå¯é€‰ï¼‰

å°†èƒŒæ™¯å›¾æ”¾åœ¨ `scenes/zone_02/background.jpg`

### æ­¥éª¤ 4ï¼šåˆ›å»º items.jsonï¼ˆå¯é€‰ï¼‰

åœ¨ `scenes/zone_02/items.json` ä¸­ï¼š

```json
{
  "items": [
    {
      "itemId": "item_003",
      "name": "æŸåçš„æ•°æ®æ¿",
      "type": "information",
      "desc": "åŒ…å«éƒ¨åˆ†ç ”ç©¶æ•°æ®çš„ç”µå­æ¿ï¼Œå¯èƒ½æä¾›å…³äºå¼‚å¸¸ç°è±¡çš„çº¿ç´¢",
      "meta": {
        "grantKnowledge": "research_log_fragment"
      }
    }
  ]
}
```

### æ­¥éª¤ 5ï¼šåœ¨æ¸¸æˆä¸­ä½¿ç”¨

ä¿®æ”¹å‰ç«¯ä»£ç ï¼Œå°† `sceneId` è®¾ç½®ä¸º `'zone_02'`ï¼š

```typescript
// In LLMGameUI.tsx, line ~45
const newSession: GameSession = {
  runId: generateRunId(),
  sceneId: 'zone_02',  // â† ä¿®æ”¹è¿™é‡Œ
  // ...
};
```

---

## ğŸ”§ é…ç½® LLM æä¾›å•†

### å½“å‰çŠ¶æ€ï¼šMock LLM

é»˜è®¤ä½¿ç”¨ **Mock LLM**ï¼ˆç¡¬ç¼–ç å“åº”ï¼‰ï¼Œç”¨äºæµ‹è¯•æ¶æ„ã€‚

### åˆ‡æ¢åˆ°çœŸå® LLM

#### 1. OpenAI

åœ¨ `packages/server/src/services/llm-client.ts:102-121` ä¸­å·²æœ‰ç¤ºä¾‹ä»£ç ï¼Œä¿®æ”¹å¦‚ä¸‹ï¼š

```typescript
private async generateOpenAI(prompt: string): Promise<LLMGenerationResponse> {
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${this.config.apiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: this.config.model || 'gpt-4',
      messages: [{ role: 'user', content: prompt }],
      temperature: this.config.temperature,
      max_tokens: this.config.maxTokens,
    })
  });

  const data = await response.json();
  const outputText = data.choices[0].message.content;

  // Parse and return
  return {
    success: true,
    rawOutput: outputText,
    usedFallback: false,
  };
}
```

**æ³¨æ„**ï¼šå°†æœ€åçš„ `return this.generateMock(prompt);` æ”¹ä¸ºä¸Šè¿°å®é™…è°ƒç”¨ä»£ç ã€‚

ç„¶ååœ¨ `packages/server/src/services/llm-client.ts:196-201` ä¿®æ”¹é»˜è®¤é…ç½®ï¼š

```typescript
export function getLLMClient(config?: LLMClientConfig): LLMClient {
  if (!llmClientInstance) {
    // ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    const defaultConfig: LLMClientConfig = {
      provider: (process.env.LLM_PROVIDER as 'mock' | 'openai' | 'anthropic') || 'mock',
      apiKey: process.env.OPENAI_API_KEY || process.env.ANTHROPIC_API_KEY,
      model: process.env.LLM_MODEL || 'gpt-4',
      temperature: 0.7,
      maxTokens: 1000,
    };
    llmClientInstance = new LLMClient(config || defaultConfig);
  }
  return llmClientInstance;
}
```

ç„¶ååˆ›å»º `.env` æ–‡ä»¶ï¼ˆåœ¨ `packages/server/` ç›®å½•ï¼‰ï¼š

```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-api-key-here
LLM_MODEL=gpt-4
```

#### 2. Anthropic Claude

ç±»ä¼¼æ­¥éª¤ï¼Œä¿®æ”¹ `generateAnthropic` æ–¹æ³•å¹¶é…ç½® API Keyã€‚

---

## ğŸ§ª æµ‹è¯• LLM æ¥å£

### ç›´æ¥è°ƒç”¨ API

```bash
curl -X POST http://localhost:3001/api/game/step \
  -H "Content-Type: application/json" \
  -d '{
    "sceneId": "zone_01",
    "gameState": {
      "player": {
        "visible": { "health": 100, "stamina": 100, "supplies": 80 },
        "inventory": [],
        "persistent": { "anomalousArtifacts": [], "deathCount": 0 }
      },
      "turnCount": 0
    },
    "history": [],
    "runId": "test_001"
  }'
```

### é¢„æœŸå“åº”

```json
{
  "success": true,
  "data": {
    "narrative": "ä½ ç«™åœ¨ç¦åŒºè¾¹ç¼˜ï¼Œè¿œå¤„çš„å±±å¡ç¬¼ç½©åœ¨è–„é›¾ä¸­...",
    "narrativeSource": "environment",
    "choices": [
      {
        "id": "choice_1",
        "text": "ç»§ç»­å‘å‰ï¼Œæ²¿ç€å±±å¡è¾¹ç¼˜å‰è¿›",
        "riskHint": "ä½“åŠ›å¯èƒ½ä¸‹é™"
      },
      {
        "id": "choice_2",
        "text": "åœä¸‹æ¥ä»”ç»†è§‚å¯Ÿå‘¨å›´ç¯å¢ƒ",
        "riskHint": "æ¶ˆè€—æ—¶é—´"
      }
    ],
    "tags": ["exploration", "anomaly_hint"],
    "background": "/scenes/zone_01/background.jpg",
    "backgroundFallback": "#0b0f14",
    "sceneInfo": {
      "sceneId": "zone_01",
      "name": "æœªçŸ¥ç¦åŒºå…¥å£",
      "dangerLevel": 2
    },
    "meta": {
      "usedFallback": false
    }
  }
}
```

---

## ğŸ“Š ç³»ç»ŸéªŒæ”¶æ ‡å‡†ï¼ˆå·²è¾¾æˆï¼‰

- âœ… èƒ½åŠ è½½ `scenes/zone_01/scene.json`
- âœ… èƒ½æ„é€  contextï¼ˆåŒ…å« scene/player/history/metaï¼‰
- âœ… èƒ½é€šè¿‡ Prompt æ¨¡æ¿ç”Ÿæˆæœ€ç»ˆ prompt
- âœ… èƒ½è·å¾—ç»“æ„åŒ– LLM è¾“å‡ºï¼ˆmock å®ç°ï¼‰
- âœ… å‰ç«¯å¯å±•ç¤ºï¼šèƒŒæ™¯ã€narrative æ–‡æœ¬ã€2-4 ä¸ª choices
- âœ… ç‚¹å‡»é€‰é¡¹åï¼šhistory è¿½åŠ æ‘˜è¦ã€å†æ¬¡è°ƒç”¨ LLMã€UI æ›´æ–°è¿›å…¥ä¸‹ä¸€æ­¥

---

## ğŸ” è°ƒè¯•ä¸æ—¥å¿—

### æŸ¥çœ‹ LLM è¾“å…¥ï¼ˆåç«¯æ—¥å¿—ï¼‰

è¿è¡Œåç«¯æ—¶ï¼Œæ§åˆ¶å°ä¼šæ‰“å°ï¼š

```
Generated prompt (first 200 chars): # Scene and Choices Generation Prompt

You are a narrative generation engine...
```

### æŸ¥çœ‹ LLM è¾“å‡ºï¼ˆæµè§ˆå™¨æ§åˆ¶å°ï¼‰

å‰ç«¯ä¼šæ˜¾ç¤ºï¼š
- `usedFallback: true/false` - æ˜¯å¦ä½¿ç”¨é™çº§ç­–ç•¥
- `llmError` - LLM é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰

### Schema æ ¡éªŒæ—¥å¿—

å¦‚æœ LLM è¾“å‡ºä¸ç¬¦åˆè§„èŒƒï¼Œåç«¯ä¼šæ‰“å°ï¼š

```
LLM output validation failed: [
  "narrative.text must be at least 10 characters",
  "choices[0].id must match pattern \"choice_N\""
]
```

---

## ğŸš¨ å¸¸è§é—®é¢˜

### Q: æŠ¥é”™ "Cannot POST /api/game/step"

**åŸå› **ï¼šåç«¯æœåŠ¡æœªå¯åŠ¨æˆ–ç«¯å£é”™è¯¯ã€‚

**è§£å†³**ï¼š
1. ç¡®è®¤åç«¯è¿è¡Œåœ¨ `http://localhost:3001`
2. æ£€æŸ¥å‰ç«¯ API è°ƒç”¨æ˜¯å¦ä½¿ç”¨ç›¸å¯¹è·¯å¾„ `/api/game/step`ï¼ˆå·²ä¿®å¤ï¼‰

### Q: ç•Œé¢æ˜¾ç¤º "âš  LLM ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é™çº§æ–‡æœ¬"

**åŸå› **ï¼šMock LLM æˆ–çœŸå® LLM è¿”å›æ ¼å¼ä¸æ­£ç¡®ã€‚

**è§£å†³**ï¼š
1. æŸ¥çœ‹åç«¯æ—¥å¿—ä¸­çš„ schema æ ¡éªŒé”™è¯¯
2. æ£€æŸ¥ `llm-client.ts` çš„è¾“å‡ºæ ¼å¼
3. ç¡®ä¿è¾“å‡ºç¬¦åˆ `prompts/schemas/llm_output.schema.json`

### Q: å¦‚ä½•ç¦ç”¨ mockï¼Œå¼ºåˆ¶ä½¿ç”¨çœŸå® LLMï¼Ÿ

ä¿®æ”¹ `packages/server/src/routes/game-routes.ts:172-197` ä¸­çš„ `getGameStepController` åˆå§‹åŒ–ï¼š

```typescript
const llmClient = new LLMClient({
  provider: 'openai',  // æˆ– 'anthropic'
  apiKey: process.env.OPENAI_API_KEY,
  temperature: 0.7,
  maxTokens: 1000,
});
```

### Q: åœºæ™¯èƒŒæ™¯å›¾ä¸æ˜¾ç¤º

**æ£€æŸ¥é¡¹**ï¼š
1. å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼š`scenes/zone_01/background.jpg`
2. åç«¯é™æ€æ–‡ä»¶æœåŠ¡æ˜¯å¦å¯åŠ¨ï¼ˆå·²åœ¨ `packages/server/src/index.ts:29-30` é…ç½®ï¼‰
3. æµè§ˆå™¨æ§åˆ¶å°æ˜¯å¦æœ‰ 404 é”™è¯¯

---

## ğŸ“š æ‰©å±•é˜…è¯»

### Prompt æ¨¡æ¿ç¼–å†™æŒ‡å—

æŸ¥çœ‹ `prompts/templates/scene_and_choices.prompt.md`ï¼Œäº†è§£å¦‚ä½•ï¼š
- çº¦æŸ LLM è¾“å‡ºæ ¼å¼
- æ³¨å…¥ä¸Šä¸‹æ–‡å ä½ç¬¦
- å®šä¹‰å™äº‹é£æ ¼ï¼ˆå…‹åˆ¶ã€å‹æŠ‘ã€ä¸ç¡®å®šæ€§ï¼‰

### æ·»åŠ æ–°çš„ Prompt ç±»å‹

1. åœ¨ `prompts/templates/` åˆ›å»ºæ–°æ¨¡æ¿æ–‡ä»¶
2. åœ¨ `prompt-renderer.ts` æ·»åŠ æ–°ç±»å‹
3. åœ¨ `context-builder.ts` æ·»åŠ å¯¹åº”çš„ä¸Šä¸‹æ–‡æ„é€ é€»è¾‘

### Schema æ‰©å±•

ä¿®æ”¹ `prompts/schemas/llm_output.schema.json`ï¼Œå¯ä»¥æ·»åŠ ï¼š
- æ–°çš„ narrative source ç±»å‹
- æ–°çš„ tag ç±»å‹
- é¢å¤–çš„å…ƒæ•°æ®å­—æ®µ

---

## ğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®

1. **æ¥å…¥çœŸå® LLM**ï¼šæ›¿æ¢ mock å®ç°ä¸º OpenAI/Anthropic API
2. **å®Œå–„è§„åˆ™å¼•æ“**ï¼šåœ¨ `makeChoice` ä¸­å®ç°çœŸå®çš„åæœè®¡ç®—
3. **å¤šåœºæ™¯æ”¯æŒ**ï¼šæ·»åŠ åœºæ™¯åˆ‡æ¢é€»è¾‘ï¼ˆä» zone_01 åˆ° zone_02ï¼‰
4. **æŒä¹…åŒ–å­˜å‚¨**ï¼šä¿å­˜æ¸¸æˆè¿›åº¦åˆ°æ•°æ®åº“
5. **ä¼˜åŒ– Prompt**ï¼šæ ¹æ®å®é™… LLM è¾“å‡ºè´¨é‡è°ƒæ•´æ¨¡æ¿

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. åç«¯æ—¥å¿—ï¼ˆè¿è¡Œ `npm run dev` çš„ç»ˆç«¯ï¼‰
2. æµè§ˆå™¨æ§åˆ¶å°ï¼ˆF12 â†’ Consoleï¼‰
3. ç½‘ç»œè¯·æ±‚ï¼ˆF12 â†’ Network â†’ XHRï¼‰

**é‡è¦æé†’**ï¼šå½“å‰ç³»ç»Ÿ**å®Œå…¨ä¾èµ– LLM**ï¼Œå¦‚æœ LLM ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨é™çº§å™äº‹ã€‚ç¡®ä¿ LLM æœåŠ¡æ­£å¸¸è¿è¡Œä»¥è·å¾—æœ€ä½³ä½“éªŒã€‚
